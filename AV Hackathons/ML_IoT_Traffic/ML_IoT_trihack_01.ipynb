{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach to predicting traffic volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48120 entries, 0 to 48119\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   DateTime  48120 non-null  object\n",
      " 1   Junction  48120 non-null  int64 \n",
      " 2   Vehicles  48120 non-null  int64 \n",
      " 3   ID        48120 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DateTime'] = pd.to_datetime(train['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['ID'] = train.ID.astype('str')\n",
    "train['Junction'] = train.Junction.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48120 entries, 0 to 48119\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   DateTime  48120 non-null  datetime64[ns]\n",
      " 1   Junction  48120 non-null  object        \n",
      " 2   Vehicles  48120 non-null  int64         \n",
      " 3   ID        48120 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicles</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48120.000000</td>\n",
       "      <td>4.812000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.791334</td>\n",
       "      <td>2.016330e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.750063</td>\n",
       "      <td>5.944854e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.015110e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.016042e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.016093e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.017023e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.017063e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Vehicles            ID\n",
       "count  48120.000000  4.812000e+04\n",
       "mean      22.791334  2.016330e+10\n",
       "std       20.750063  5.944854e+06\n",
       "min        1.000000  2.015110e+10\n",
       "25%        9.000000  2.016042e+10\n",
       "50%       15.000000  2.016093e+10\n",
       "75%       29.000000  2.017023e+10\n",
       "max      180.000000  2.017063e+10"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Junction</th>\n",
       "      <th>Vehicles</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20151101001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20151101011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20151101021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20151101031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20151101041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime Junction  Vehicles           ID\n",
       "0 2015-11-01 00:00:00        1        15  20151101001\n",
       "1 2015-11-01 01:00:00        1        13  20151101011\n",
       "2 2015-11-01 02:00:00        1        10  20151101021\n",
       "3 2015-11-01 03:00:00        1         7  20151101031\n",
       "4 2015-11-01 04:00:00        1         9  20151101041"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.set_index('DateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = train[['Junction', 'ID']],train.Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Junction           ID\n",
       " 0            1  20151101001\n",
       " 1            1  20151101011\n",
       " 2            1  20151101021\n",
       " 3            1  20151101031\n",
       " 4            1  20151101041\n",
       " ...        ...          ...\n",
       " 48115        4  20170630194\n",
       " 48116        4  20170630204\n",
       " 48117        4  20170630214\n",
       " 48118        4  20170630224\n",
       " 48119        4  20170630234\n",
       " \n",
       " [48120 rows x 2 columns],\n",
       " 0        15\n",
       " 1        13\n",
       " 2        10\n",
       " 3         7\n",
       " 4         9\n",
       "          ..\n",
       " 48115    11\n",
       " 48116    30\n",
       " 48117    16\n",
       " 48118    22\n",
       " 48119    12\n",
       " Name: Vehicles, Length: 48120, dtype: int64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11808 entries, 0 to 11807\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   DateTime  11808 non-null  object\n",
      " 1   Junction  11808 non-null  int64 \n",
      " 2   ID        11808 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 276.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Junction</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/1/17 0:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/1/17 1:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/1/17 2:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/1/17 3:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/1/17 4:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DateTime  Junction           ID\n",
       "0  7/1/17 0:00         1  20170701001\n",
       "1  7/1/17 1:00         1  20170701011\n",
       "2  7/1/17 2:00         1  20170701021\n",
       "3  7/1/17 3:00         1  20170701031\n",
       "4  7/1/17 4:00         1  20170701041"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[[\"Junction\", \"ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.58028625, -0.25456281, -0.24685501,  0.47663231, -1.31800917,\n",
       "        0.09311527,  0.25390948, -0.04225175, -0.15623799, -2.47540336])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor(random_state=101)\n",
    "cross_val_score(reg, X, y, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03639293, 0.0358882 , 0.02615023, 0.02374911, 0.02341986,\n",
       "        0.0246501 , 0.02451801, 0.02837729, 0.02736306, 0.02395892]),\n",
       " 'score_time': array([0.00299597, 0.00211191, 0.00192404, 0.00184298, 0.00176191,\n",
       "        0.00175095, 0.00174379, 0.00178385, 0.00187016, 0.00184917]),\n",
       " 'test_score': array([-5.58028625, -0.25456281, -0.24685501,  0.47663231, -1.31800917,\n",
       "         0.09311527,  0.25390948, -0.04225175, -0.15623799, -2.47540336])}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(reg, X, y, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X,y)\n",
    "dt_prediction = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt_df = pd.DataFrame({\"ID\":X_test[\"ID\"], \"Vehicles\": dt_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt_df.to_csv(\"prediction_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01675129, 0.01712608, 0.0183599 , 0.01554036, 0.0147512 ,\n",
       "        0.0100472 , 0.01185799, 0.01072121, 0.00996876, 0.00996614]),\n",
       " 'score_time': array([0.0025506 , 0.00246286, 0.00272918, 0.00254679, 0.00167298,\n",
       "        0.00163507, 0.00169396, 0.00165915, 0.00157619, 0.00164819]),\n",
       " 'test_score': array([-0.52392203, -0.32145083, -1.2259157 ,  0.06428272, -6.16981927,\n",
       "        -4.33694396, -1.29240807, -0.62120739, -0.12800758, -0.09686078])}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "cross_validate(lin_reg, X, y, cv= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5162125504761439"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X,y).score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"Vehicles\":pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"ID\"] = test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X,y, test_size = 0.3, random_state = 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5181487898841317"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(trainX, trainY).score(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.9990691 ,  7.71350541, 37.21159822, ..., 22.12288661,\n",
       "       34.54320037,  6.39327788])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(trainX, trainY).predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.30762572920628"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(lin_reg.fit(trainX, trainY).predict(testX), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.52135978265506"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(lin_reg.fit(trainX, trainY).predict(testX), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5135997972051176"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_lasso = Lasso()\n",
    "lin_lasso.fit(X,y).score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213.71908462187866"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(lin_lasso.fit(trainX, trainY).predict(testX), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.395333545900082"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(lin_lasso.fit(trainX, trainY).predict(testX), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.516212550222449"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ridge = Ridge()\n",
    "lin_ridge.fit(X,y).score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.3077594912651"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(lin_ridge.fit(trainX, trainY).predict(testX), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.521273928777983"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(lin_ridge.fit(trainX, trainY).predict(testX), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5161960221853487"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_elastic = ElasticNet(alpha = 10e-3)\n",
    "lin_elastic.fit(X,y).score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.33847717676767"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(lin_elastic.fit(trainX, trainY).predict(testX), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.506352839792045"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(lin_elastic.fit(trainX, trainY).predict(testX), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lin_elastic.fit(X,y).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"ID\":X_test[\"ID\"], \"Vehicles\": prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170701001</td>\n",
       "      <td>50.255056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170701011</td>\n",
       "      <td>50.255069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170701021</td>\n",
       "      <td>50.255083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170701031</td>\n",
       "      <td>50.255096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170701041</td>\n",
       "      <td>50.255109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11803</th>\n",
       "      <td>20171031194</td>\n",
       "      <td>5.978844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11804</th>\n",
       "      <td>20171031204</td>\n",
       "      <td>5.978857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805</th>\n",
       "      <td>20171031214</td>\n",
       "      <td>5.978871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>20171031224</td>\n",
       "      <td>5.978884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11807</th>\n",
       "      <td>20171031234</td>\n",
       "      <td>5.978897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11808 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID   Vehicles\n",
       "0      20170701001  50.255056\n",
       "1      20170701011  50.255069\n",
       "2      20170701021  50.255083\n",
       "3      20170701031  50.255096\n",
       "4      20170701041  50.255109\n",
       "...            ...        ...\n",
       "11803  20171031194   5.978844\n",
       "11804  20171031204   5.978857\n",
       "11805  20171031214   5.978871\n",
       "11806  20171031224   5.978884\n",
       "11807  20171031234   5.978897\n",
       "\n",
       "[11808 rows x 2 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _tflow_select-2.3.0        |              mkl           3 KB\n",
      "    absl-py-0.9.0              |           py37_0         164 KB\n",
      "    astor-0.8.0                |           py37_0          46 KB\n",
      "    c-ares-1.15.0              |    h1de35cc_1001          73 KB\n",
      "    conda-4.8.3                |           py37_0         2.8 MB\n",
      "    gast-0.3.3                 |             py_0          14 KB\n",
      "    grpcio-1.16.1              |   py37h044775b_1         840 KB\n",
      "    keras-2.3.1                |                0          12 KB\n",
      "    keras-applications-1.0.8   |             py_0          32 KB\n",
      "    keras-base-2.3.1           |           py37_0         501 KB\n",
      "    keras-preprocessing-1.1.0  |             py_1          37 KB\n",
      "    libprotobuf-3.11.4         |       hd9629dc_0         2.6 MB\n",
      "    libssh2-1.9.0              |       ha12b0ac_1         250 KB\n",
      "    markdown-3.1.1             |           py37_0         117 KB\n",
      "    protobuf-3.11.4            |   py37h0a44026_0         628 KB\n",
      "    setuptools-46.0.0          |           py37_0         511 KB\n",
      "    tensorboard-1.14.0         |   py37h80053f4_0         3.1 MB\n",
      "    tensorflow-1.14.0          |mkl_py37h085be34_0           5 KB\n",
      "    tensorflow-base-1.14.0     |mkl_py37h5a24fda_0        71.1 MB\n",
      "    tensorflow-estimator-1.14.0|             py_0         261 KB\n",
      "    termcolor-1.1.0            |           py37_1           8 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        83.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _tflow_select      pkgs/main/osx-64::_tflow_select-2.3.0-mkl\n",
      "  absl-py            pkgs/main/osx-64::absl-py-0.9.0-py37_0\n",
      "  astor              pkgs/main/osx-64::astor-0.8.0-py37_0\n",
      "  c-ares             pkgs/main/osx-64::c-ares-1.15.0-h1de35cc_1001\n",
      "  gast               pkgs/main/noarch::gast-0.3.3-py_0\n",
      "  grpcio             pkgs/main/osx-64::grpcio-1.16.1-py37h044775b_1\n",
      "  keras              pkgs/main/osx-64::keras-2.3.1-0\n",
      "  keras-applications pkgs/main/noarch::keras-applications-1.0.8-py_0\n",
      "  keras-base         pkgs/main/osx-64::keras-base-2.3.1-py37_0\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1\n",
      "  libprotobuf        pkgs/main/osx-64::libprotobuf-3.11.4-hd9629dc_0\n",
      "  markdown           pkgs/main/osx-64::markdown-3.1.1-py37_0\n",
      "  protobuf           pkgs/main/osx-64::protobuf-3.11.4-py37h0a44026_0\n",
      "  tensorboard        pkgs/main/osx-64::tensorboard-1.14.0-py37h80053f4_0\n",
      "  tensorflow         pkgs/main/osx-64::tensorflow-1.14.0-mkl_py37h085be34_0\n",
      "  tensorflow-base    pkgs/main/osx-64::tensorflow-base-1.14.0-mkl_py37h5a24fda_0\n",
      "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-1.14.0-py_0\n",
      "  termcolor          pkgs/main/osx-64::termcolor-1.1.0-py37_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                        4.8.2-py37_0 --> 4.8.3-py37_0\n",
      "  libssh2                                  1.8.2-ha12b0ac_0 --> 1.9.0-ha12b0ac_1\n",
      "  setuptools                                  45.2.0-py37_0 --> 46.0.0-py37_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.8.3          | 2.8 MB    | ##################################### | 100% \n",
      "absl-py-0.9.0        | 164 KB    | ##################################### | 100% \n",
      "keras-2.3.1          | 12 KB     | ##################################### | 100% \n",
      "setuptools-46.0.0    | 511 KB    | ##################################### | 100% \n",
      "tensorflow-estimator | 261 KB    | ##################################### | 100% \n",
      "libssh2-1.9.0        | 250 KB    | ##################################### | 100% \n",
      "keras-base-2.3.1     | 501 KB    | ##################################### | 100% \n",
      "astor-0.8.0          | 46 KB     | ##################################### | 100% \n",
      "keras-preprocessing- | 37 KB     | ##################################### | 100% \n",
      "_tflow_select-2.3.0  | 3 KB      | ##################################### | 100% \n",
      "tensorflow-base-1.14 | 71.1 MB   | ##################################### | 100% \n",
      "termcolor-1.1.0      | 8 KB      | ##################################### | 100% \n",
      "keras-applications-1 | 32 KB     | ##################################### | 100% \n",
      "tensorboard-1.14.0   | 3.1 MB    | ##################################### | 100% \n",
      "tensorflow-1.14.0    | 5 KB      | ##################################### | 100% \n",
      "libprotobuf-3.11.4   | 2.6 MB    | ##################################### | 100% \n",
      "gast-0.3.3           | 14 KB     | ##################################### | 100% \n",
      "grpcio-1.16.1        | 840 KB    | ##################################### | 100% \n",
      "c-ares-1.15.0        | 73 KB     | ##################################### | 100% \n",
      "markdown-3.1.1       | 117 KB    | ##################################### | 100% \n",
      "protobuf-3.11.4      | 628 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss: 230.2649\n",
      "Epoch 2/10\n",
      " - 4s - loss: 140.9574\n",
      "Epoch 3/10\n",
      " - 4s - loss: 137.9913\n",
      "Epoch 4/10\n",
      " - 4s - loss: 137.4890\n",
      "Epoch 5/10\n",
      " - 5s - loss: 137.2069\n",
      "Epoch 6/10\n",
      " - 4s - loss: 136.8326\n",
      "Epoch 7/10\n",
      " - 4s - loss: 136.7601\n",
      "Epoch 8/10\n",
      " - 4s - loss: 136.8356\n",
      "Epoch 9/10\n",
      " - 4s - loss: 136.5841\n",
      "Epoch 10/10\n",
      " - 4s - loss: 136.6900\n",
      "Epoch 1/10\n",
      " - 5s - loss: 214.5929\n",
      "Epoch 2/10\n",
      " - 4s - loss: 131.0442\n",
      "Epoch 3/10\n",
      " - 4s - loss: 121.3044\n",
      "Epoch 4/10\n",
      " - 4s - loss: 120.7792\n",
      "Epoch 5/10\n",
      " - 4s - loss: 120.5200\n",
      "Epoch 6/10\n",
      " - 4s - loss: 120.5242\n",
      "Epoch 7/10\n",
      " - 4s - loss: 120.4289\n",
      "Epoch 8/10\n",
      " - 5s - loss: 120.5228\n",
      "Epoch 9/10\n",
      " - 4s - loss: 120.3839\n",
      "Epoch 10/10\n",
      " - 4s - loss: 120.4406\n",
      "Epoch 1/10\n",
      " - 5s - loss: 152.8459\n",
      "Epoch 2/10\n",
      " - 5s - loss: 100.4097\n",
      "Epoch 3/10\n",
      " - 5s - loss: 97.6344\n",
      "Epoch 4/10\n",
      " - 4s - loss: 96.1987\n",
      "Epoch 5/10\n",
      " - 4s - loss: 94.2705\n",
      "Epoch 6/10\n",
      " - 4s - loss: 91.8215\n",
      "Epoch 7/10\n",
      " - 5s - loss: 88.8282\n",
      "Epoch 8/10\n",
      " - 4s - loss: 86.7618\n",
      "Epoch 9/10\n",
      " - 4s - loss: 86.1447\n",
      "Epoch 10/10\n",
      " - 4s - loss: 85.7400\n",
      "Epoch 1/10\n",
      " - 5s - loss: 231.7760\n",
      "Epoch 2/10\n",
      " - 4s - loss: 153.9083\n",
      "Epoch 3/10\n",
      " - 4s - loss: 152.8816\n",
      "Epoch 4/10\n",
      " - 4s - loss: 152.6194\n",
      "Epoch 5/10\n",
      " - 4s - loss: 152.4664\n",
      "Epoch 6/10\n",
      " - 4s - loss: 152.7728\n",
      "Epoch 7/10\n",
      " - 4s - loss: 152.7236\n",
      "Epoch 8/10\n",
      " - 4s - loss: 152.9171\n",
      "Epoch 9/10\n",
      " - 4s - loss: 152.7070\n",
      "Epoch 10/10\n",
      " - 5s - loss: 152.8272\n",
      "Epoch 1/10\n",
      " - 6s - loss: 246.2873\n",
      "Epoch 2/10\n",
      " - 5s - loss: 159.0162\n",
      "Epoch 3/10\n",
      " - 5s - loss: 155.6354\n",
      "Epoch 4/10\n",
      " - 4s - loss: 155.0320\n",
      "Epoch 5/10\n",
      " - 4s - loss: 154.8376\n",
      "Epoch 6/10\n",
      " - 4s - loss: 154.5035\n",
      "Epoch 7/10\n",
      " - 4s - loss: 154.5811\n",
      "Epoch 8/10\n",
      " - 4s - loss: 154.3963\n",
      "Epoch 9/10\n",
      " - 4s - loss: 154.5019\n",
      "Epoch 10/10\n",
      " - 4s - loss: 154.4875\n",
      "Epoch 1/10\n",
      " - 6s - loss: 234.4320\n",
      "Epoch 2/10\n",
      " - 4s - loss: 151.6266\n",
      "Epoch 3/10\n",
      " - 4s - loss: 151.5802\n",
      "Epoch 4/10\n",
      " - 4s - loss: 151.4824\n",
      "Epoch 5/10\n",
      " - 4s - loss: 151.4539\n",
      "Epoch 6/10\n",
      " - 4s - loss: 151.4461\n",
      "Epoch 7/10\n",
      " - 4s - loss: 151.2546\n",
      "Epoch 8/10\n",
      " - 4s - loss: 151.3550\n",
      "Epoch 9/10\n",
      " - 4s - loss: 151.4337\n",
      "Epoch 10/10\n",
      " - 4s - loss: 151.1842\n",
      "Epoch 1/10\n",
      " - 5s - loss: 244.6260\n",
      "Epoch 2/10\n",
      " - 4s - loss: 151.2310\n",
      "Epoch 3/10\n",
      " - 4s - loss: 148.6870\n",
      "Epoch 4/10\n",
      " - 4s - loss: 148.5915\n",
      "Epoch 5/10\n",
      " - 4s - loss: 148.4995\n",
      "Epoch 6/10\n",
      " - 4s - loss: 148.5615\n",
      "Epoch 7/10\n",
      " - 5s - loss: 148.5325\n",
      "Epoch 8/10\n",
      " - 4s - loss: 148.5273\n",
      "Epoch 9/10\n",
      " - 4s - loss: 148.5493\n",
      "Epoch 10/10\n",
      " - 4s - loss: 148.4090\n",
      "Epoch 1/10\n",
      " - 6s - loss: 237.1508\n",
      "Epoch 2/10\n",
      " - 5s - loss: 152.5326\n",
      "Epoch 3/10\n",
      " - 5s - loss: 146.9385\n",
      "Epoch 4/10\n",
      " - 5s - loss: 145.7113\n",
      "Epoch 5/10\n",
      " - 5s - loss: 145.4706\n",
      "Epoch 6/10\n",
      " - 4s - loss: 145.4876\n",
      "Epoch 7/10\n",
      " - 4s - loss: 145.4435\n",
      "Epoch 8/10\n",
      " - 4s - loss: 145.2238\n",
      "Epoch 9/10\n",
      " - 4s - loss: 145.1293\n",
      "Epoch 10/10\n",
      " - 4s - loss: 144.8511\n",
      "Epoch 1/10\n",
      " - 6s - loss: 219.6886\n",
      "Epoch 2/10\n",
      " - 4s - loss: 144.6306\n",
      "Epoch 3/10\n",
      " - 4s - loss: 144.2700\n",
      "Epoch 4/10\n",
      " - 5s - loss: 144.2607\n",
      "Epoch 5/10\n",
      " - 4s - loss: 144.3997\n",
      "Epoch 6/10\n",
      " - 5s - loss: 144.1221\n",
      "Epoch 7/10\n",
      " - 5s - loss: 144.2614\n",
      "Epoch 8/10\n",
      " - 5s - loss: 144.4805\n",
      "Epoch 9/10\n",
      " - 4s - loss: 144.3031\n",
      "Epoch 10/10\n",
      " - 4s - loss: 144.4134\n",
      "Epoch 1/10\n",
      " - 6s - loss: 235.2597\n",
      "Epoch 2/10\n",
      " - 4s - loss: 153.5417\n",
      "Epoch 3/10\n",
      " - 5s - loss: 152.7555\n",
      "Epoch 4/10\n",
      " - 5s - loss: 152.7193\n",
      "Epoch 5/10\n",
      " - 5s - loss: 152.5393\n",
      "Epoch 6/10\n",
      " - 4s - loss: 152.6787\n",
      "Epoch 7/10\n",
      " - 4s - loss: 152.6078\n",
      "Epoch 8/10\n",
      " - 4s - loss: 152.6018\n",
      "Epoch 9/10\n",
      " - 4s - loss: 152.7451\n",
      "Epoch 10/10\n",
      " - 4s - loss: 152.5049\n",
      "Larger: -184.75 (154.18) MSE\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(20, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(20, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "#estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=10, batch_size=20, verbose=2)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 6s - loss: 206.1492\n",
      "Epoch 2/10\n",
      " - 5s - loss: 143.0825\n",
      "Epoch 3/10\n",
      " - 5s - loss: 141.6469\n",
      "Epoch 4/10\n",
      " - 5s - loss: 141.4112\n",
      "Epoch 5/10\n",
      " - 5s - loss: 141.5023\n",
      "Epoch 6/10\n",
      " - 5s - loss: 141.2622\n",
      "Epoch 7/10\n",
      " - 5s - loss: 141.4958\n",
      "Epoch 8/10\n",
      " - 6s - loss: 141.3571\n",
      "Epoch 9/10\n",
      " - 5s - loss: 141.3594\n",
      "Epoch 10/10\n",
      " - 5s - loss: 141.3815\n"
     ]
    }
   ],
   "source": [
    "nn_prediction = pipeline.fit(X,y).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(20, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(20, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimators2 = []\n",
    "estimators2.append(('standardize', StandardScaler()))\n",
    "estimators2.append(('mlp', KerasRegressor(build_fn=nn_model, epochs=30, batch_size=1, verbose=2, validation_split = 0.20)))\n",
    "pipeline2 = Pipeline(estimators2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38496 samples, validate on 9624 samples\n",
      "Epoch 1/30\n",
      " - 89s - loss: 179.2683 - val_loss: 103.0725\n",
      "Epoch 2/30\n",
      " - 87s - loss: 158.8929 - val_loss: 102.6515\n",
      "Epoch 3/30\n",
      " - 86s - loss: 158.9395 - val_loss: 103.3399\n",
      "Epoch 4/30\n",
      " - 96s - loss: 159.4183 - val_loss: 102.2754\n",
      "Epoch 5/30\n",
      " - 95s - loss: 160.4980 - val_loss: 101.9758\n",
      "Epoch 6/30\n",
      " - 86s - loss: 161.2708 - val_loss: 103.4045\n",
      "Epoch 7/30\n",
      " - 86s - loss: 162.9724 - val_loss: 99.6534\n",
      "Epoch 8/30\n",
      " - 86s - loss: 163.7270 - val_loss: 111.1190\n",
      "Epoch 9/30\n",
      " - 100s - loss: 164.0456 - val_loss: 105.8191\n",
      "Epoch 10/30\n",
      " - 101s - loss: 164.2689 - val_loss: 99.9730\n",
      "Epoch 11/30\n",
      " - 101s - loss: 163.9355 - val_loss: 100.3633\n",
      "Epoch 12/30\n",
      " - 101s - loss: 164.1809 - val_loss: 103.2956\n",
      "Epoch 13/30\n",
      " - 101s - loss: 165.0479 - val_loss: 104.2694\n",
      "Epoch 14/30\n",
      " - 100s - loss: 163.7242 - val_loss: 99.6447\n",
      "Epoch 15/30\n",
      " - 89s - loss: 163.6224 - val_loss: 103.2162\n",
      "Epoch 16/30\n",
      " - 86s - loss: 163.6986 - val_loss: 99.7123\n",
      "Epoch 17/30\n",
      " - 87s - loss: 164.1646 - val_loss: 106.0841\n",
      "Epoch 18/30\n",
      " - 86s - loss: 164.2061 - val_loss: 101.0878\n",
      "Epoch 19/30\n",
      " - 86s - loss: 163.9015 - val_loss: 100.4771\n",
      "Epoch 20/30\n",
      " - 86s - loss: 163.6752 - val_loss: 99.3450\n",
      "Epoch 21/30\n",
      " - 86s - loss: 163.4831 - val_loss: 111.5949\n",
      "Epoch 22/30\n",
      " - 86s - loss: 164.0063 - val_loss: 102.7659\n",
      "Epoch 23/30\n",
      " - 86s - loss: 164.0259 - val_loss: 100.1405\n",
      "Epoch 24/30\n",
      " - 86s - loss: 163.7826 - val_loss: 100.1464\n",
      "Epoch 25/30\n",
      " - 86s - loss: 164.1880 - val_loss: 103.3086\n",
      "Epoch 26/30\n",
      " - 86s - loss: 163.9381 - val_loss: 101.4126\n",
      "Epoch 27/30\n",
      " - 86s - loss: 164.1366 - val_loss: 106.5952\n",
      "Epoch 28/30\n",
      " - 86s - loss: 164.3611 - val_loss: 106.0331\n",
      "Epoch 29/30\n",
      " - 86s - loss: 164.2134 - val_loss: 100.0807\n",
      "Epoch 30/30\n",
      " - 86s - loss: 164.3795 - val_loss: 102.6644\n"
     ]
    }
   ],
   "source": [
    "nn_prediction = pipeline2.fit(X,y, mlp__shuffle = True).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_nn = pd.DataFrame({\"ID\":X_test[\"ID\"], \"Vehicles\": nn_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_nn.to_csv(\"prediction_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> In the end, the best RMSE obtained for the problem using the Neural Networks was 11.24 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
